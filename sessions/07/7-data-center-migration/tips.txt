simulate a Cassandra cluster migration 
  between two data centers using Docker Compose, 
  including the migration process and shutdown of the old DC.

 --- Docker Compose Setup (2 DCs)

 --- Migration Process Simulation

Step 1: Start the initial cluster (DC1 only)
  $ docker compose up -d \
        dc1_n1 \
        dc1_n2

--- Wait for DC1 to initialize 
  check logs with 
    
    $ docker logs dc1_n1

    $ docker exec -it dc1_n1 nodetool status

Step 2: Create sample keyspace and data

  $ docker exec -it dc1_n1 cqlsh 
  
  cqlsh> CREATE KEYSPACE migration_ks WITH replication = { 'class': 'NetworkTopologyStrategy', 'DC1': 2 };

  cqlsh> CREATE TABLE migration_ks.users ( user_id uuid PRIMARY KEY, username text, email text );

  cqlsh> INSERT INTO migration_ks.users (user_id, username, email) VALUES (uuid(), 'user1', 'user1@example.com');

  cqlsh> INSERT INTO migration_ks.users (user_id, username, email)    VALUES (uuid(), 'user2', 'user2@example.com');

  cqlsh> SELECT * from migration_ks.users;

Step 3: Add DC2 to the cluster

  $ docker-compose up -d dc2_n1 dc2_n2


--- Wait for DC2 to initialize 
  check logs with and activity

  $ docker logs dc2_n1 

  $ docker exec -it dc1_n1 nodetool status




Step 4: Update keyspace replication to include DC2

  $ docker exec -it dc1_n1 cqlsh

  # see replication detail such as topology class 
  #   and also data center distribution
  
  cqlsh> DESC migration_ks;

  # alter keyspace to copy to the data center 
   
  cqlsh> ALTER KEYSPACE migration_ks WITH replication = { 'class': 'NetworkTopologyStrategy', 'DC1': 2, 'DC2': 2};

  # Warnings
  # When increasing replication factor 
  # you need to run a full (-full) repair to distribute the data.

  $ docker exec -it dc1_n1 nodetool repair -full

  # see following log

      "[data and time] Repair completed successfull"

  # Verify data replication

    $ docker exec -it dc2_n1 cqlsh

    cqlsh> SELECT * from migration_ks.users;

Step 5: remove DC1 from replication
    $ docker exec -it dc2_n1 cqlsh
    
    cqlsh> ALTER KEYSPACE migration_ks WITH replication = { 'class': 'NetworkTopologyStrategy', 'DC2': 2};



Step 6: Shutdown old DC (DC1)

    $  docker-compose stop dc1_n1 dc1_n2

    $  docker-compose rm -f dc1_n1 dc1_n2

    -- Verification

        * Check cluster status:
            
            $ docker exec -it dc2_n1 nodetool status


        * Verify data is accessible:
          
            $ docker exec -it dc2_n1 cqlsh

            cqlsh> SELECT * FROM migration_ks.users;

        * add new record
            
            cqlsh> INSERT INTO migration_ks.users (user_id, username, email) VALUES (uuid(), 'user3', 'user3@example.com');

            cqlsh> SELECT * FROM migration_ks.users;

## Important Notes:

1. The migration process preserves all data while moving from DC1 to DC2
2. Clients connected to DC1 would need to be reconfigured to point to DC2
3. For production, you would want to:
   - Perform this during low-traffic periods
   - Monitor network bandwidth between DCs
   - Verify data consistency with `nodetool repair`

Would you like me to modify any part of this simulation to better match your specific requirements?