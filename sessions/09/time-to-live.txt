Use Case 

    * Session data

    * Cached data (e.g., API responses)

    * Temporary logs or events
    
        * To send a reset password link valid for 1 day.
    
        * OTP validity for set time
    
    * Compliance requirements 
        where data must be purged after a certain period.


Tips

    * TTL is used for expiring records or data.

    * Cassandra TTL are applied at column level.

    * If a record is inserted with TTL, separate TTL will be applied 
        on all the columns mentioned in the insert statement.

    * Whenever a TTL is expired in Cassandra for a column it checks 
        for all the non primary column values in the record, 
        if all values are null, record gets deleted.

    * Even after TTL is expired in Cassandra and at later point all the 
        non primary column value turns null, the record gets deleted.

    * TTL is not applicable on primary columns in Cassandra.

    * When columns with ongoing TTL are updated without TTL values, 
        the existing TTL gets removed from those columns. In other 
        words, One cannot update the value of a column with TTL 
        without altering the TTL, either by new TTL or by removing it.

    * TTL is not applicable for Cassandra column type counter.


The Core Concept

    TTL is an expiration mechanism for data. 
    When you insert or update a column, 
    you can specify a TTL value (in seconds). 
    Cassandra automatically marks that data as "tombstoned" (i.e., deleted) 
    once the specified amount of time has passed since the write operation.

    It's important to note that the TTL timer starts counting down 
    from the moment the data is written.



How It Works: A Step-by-Step Process

    start clean cassandra container

        $ docker run --rm -d -name cassandra cassandra:5.0.3

    get terminal

        $ docker exec -it cassandra bash 

        $ nodetool status

    get cqlsh

        $ cqlsh

    create keysapce and table 

        cqlsh> cqlsh> CREATE KEYSPACE rayan WITH replication = {'class': 'SimpleStrategy', 'replication_factor': 1};

        cqlsh> CREATE TABLE rayan.otp (id uuid PRIMARY KEY , value text) WITH default_time_to_live = 120;

        cqlsh> ALTER TABLE rayan.otp WITH default_time_to_live = 5;

        cqlsh> INSERT INTO rayan.otp (id , value ) VALUES ( uuid(),'1');

        cqlsh> SELECT * FROM rayan.otp;

        cqlsh> ALTER TABLE rayan.otp WITH default_time_to_live = 15;

        cqlsh> INSERT INTO rayan.otp (id , value ) VALUES ( uuid(),'1');
        cqlsh> INSERT INTO rayan.otp (id , value ) VALUES ( uuid(),'2');
        cqlsh> INSERT INTO rayan.otp (id , value ) VALUES ( uuid(),'3');

        cqlsh> SELECT  id, value,ttl(value) from rayan.otp ;

        cqlsh> INSERT INTO rayan.otp (id , value ) VALUES ( uuid(),'long') USING TTL 30;

        cqlsh> SELECT  id, value,ttl(value) from rayan.otp ;

        cqlsh> CREATE TABLE rayan.session (id int PRIMARY KEY , user_id text, session_id text) WITH default_time_to_live = 120;

        cqlsh> INSERT INTO rayan.session (id , user_id , session_id ) VALUES (1 ,'u1','s1');

        cqlsh> SELECT id,user_id,ttl(user_id),session_id,ttl(session_id)  from rayan.session ;

        cqlsh> INSERT INTO rayan.session (id , user_id , session_id ) VALUES ( 2,'u2','s2') USING TTL 300;

        cqlsh> SELECT id,user_id,ttl(user_id),session_id,ttl(session_id)  from rayan.session ;

        cqlsh> UPDATE rayan.session USING TTL 500 SET user_id = 'u1-300' WHERE id =1;

        cqlsh> SELECT id,user_id,ttl(user_id),session_id,ttl(session_id)  from rayan.session ;

        cqlsh> UPDATE rayan.session USING TTL 10 SET user_id = 'u1-10' WHERE id =1;

        cqlsh> SELECT id,user_id,ttl(user_id),session_id,ttl(session_id)  from rayan.session ;

        cqlsh> UPDATE rayan.session USING TTL 0 SET user_id = 'u2-0' , session_id = 's2-0' WHERE id =2;

        cqlsh> SELECT id,user_id,ttl(user_id),session_id,ttl(session_id)  from rayan.session ;

Important Considerations:
    
    * TTL Precision: 
        Cassandra TTL has second-level precision

    * TTL Behavior: 
        Data is not deleted immediately but during compaction

    * TTL Inheritance: 
        Row-level TTL always overrides table-level default

    * TTL = 0: 
        Means the data never expires (default behavior)

    * Negative TTL: 
        Not allowed, will cause an error


The Expiration Process (The "Garbage Collection"):

    * Read-Time Check
        This is the primary method. When a read query is executed, 
        the coordinator node checks the TTL and write time for each 
        piece of data it finds. 
        It calculates if `current_time > write_time + TTL`. 
        If true, that data is silently skipped and not returned 
        to the client. It's treated as if it doesn't exist.

    * Compaction
        This is the cleanup mechanism. During the compaction 
        process (where SSTables are merged and optimized), 
        Cassandra physically removes the expired data (tombstones) 
        from the disk files, reclaiming space.


Important Considerations and Best Practices

    1. Clock Synchronization:
        Cassandra nodes should have synchronized clocks (using NTP). 
        If clocks are skewed, expiration behavior can become 
        inconsistent across the cluster.

    2. Tombstone Overhead: 
        Expired data becomes a tombstone. A high volume of expirations 
        (e.g., millions of rows with short TTLs) can generate many 
        tombstones, which can impact performance if they exist for 
        longer than the `gc_grace_seconds` period (default: 10 days) 
        before compaction handles them.

    3. Immediate Consistency:
        Data is not deleted the instant the TTL expires. 
        It's only filtered out during reads and physically deleted 
        during compaction. If no reads occur for a long time, 
        the data will remain on disk until the next compaction, 
        even though it's logically expired.