To send a reset password link valid for 1 day.
OTP validity for set time
Opening of a bid or offer for certain period and which will be closed post that


Cassandra on the other hand is Column based storage, so the TTL their alters the data in the particular column. But wait till you read till the end.

So whenever a ttl is expiring, it verifies for all other (non-primary) columns values, If all of them are null, the record is removed automatically.

One more important thing to consider is when you insert records with ttl and again update it without ttl, the ttls will be gone on the columns you are updating.




* TTL is used for expiring records or data.
* Cassandra TTL are applied at column level.
* If a record is inserted with TTL, separate TTL will be applied on all the columns mentioned in the insert statement.
* Whenever a TTL is expired in Cassandra for a column it checks for all the non primary column values in the record, if all values are null, record gets deleted.
* Even after TTL is expired in Cassandra and at later point all the non primary column value turns null, the record gets deleted.
* TTL is not applicable on primary columns in Cassandra.
* When columns with ongoing TTL are updated without TTL values, the existing TTL gets removed from those columns. In other words, One cannot update the value of a column with TTL without altering the TTL, either by new TTL or by removing it.
* TTL is not applicable for Cassandra column type counter.

Of course. Let's break down how TTL (Time To Live) works in Apache Cassandra.

### The Core Concept

TTL is an expiration mechanism for data. When you insert or update a column, you can specify a TTL value (in seconds). Cassandra automatically marks that data as "tombstoned" (i.e., deleted) once the specified amount of time has passed since the write operation.

It's important to note that the **TTL timer starts counting down from the moment the data is written**.

---

### How It Works: A Step-by-Step Process

1.  **Write with TTL:** You perform an `INSERT` or `UPDATE` and include the `USING TTL` clause.
    ```sql
    -- Set a username to expire in 1 hour (3600 seconds)
    INSERT INTO users (user_id, username) VALUES (123, 'alice') USING TTL 3600;

    -- Update a row and set a new TTL of 1 day
    UPDATE users USING TTL 86400 SET email = 'alice@example.com' WHERE user_id = 123;
    ```

2.  **Storage with Timestamp:** Cassandra stores the data along with two crucial pieces of metadata:
    *   The **write time** (timestamp).
    *   The **TTL** value itself.

3.  **The Expiration Process (The "Garbage Collection"):**
    *   **Read-Time Check:** This is the primary method. When a read query is executed, the coordinator node checks the TTL and write time for each piece of data it finds. It calculates if `current_time > write_time + TTL`. If true, that data is silently skipped and not returned to the client. It's treated as if it doesn't exist.
    *   **Compaction:** This is the cleanup mechanism. During the **compaction** process (where SSTables are merged and optimized), Cassandra physically removes the expired data (tombstones) from the disk files, reclaiming space.

---

### Key Characteristics and Behaviors

*   **Per-Column TTL:** You can set TTL on individual columns or on an entire row.
    *   **Setting a TTL on a specific column:** Only that column will expire.
        ```sql
        INSERT INTO users (user_id, username, session_token)
        VALUES (123, 'alice', 'abc123') USING TTL 3600;
        -- Only the `session_token` expires in 1 hour. `user_id` and `username` are permanent.
        ```
    *   **Setting a TTL on a primary key (row):** The entire row will expire when the TTL is up. Under the hood, this is implemented by setting a TTL on every column in the row.

*   **TTL of Zero (`0`):** Using `TTL 0` is the explicit way to **remove TTL** from data, making it permanent.
    ```sql
    -- Make the user's email permanent (remove any previous TTL)
    UPDATE users USING TTL 0 SET email = 'permanent@example.com' WHERE user_id = 123;
    ```

*   **Default TTL:** You can set a default TTL at the table level. Any insert or update without an explicit `USING TTL` will inherit this value.
    ```sql
    CREATE TABLE temporary_sessions (
        session_id uuid PRIMARY KEY,
        data text
    ) WITH default_time_to_live = 3600; -- Data in this table expires in 1 hour by default
    ```

*   **Updating and Overwriting TTL:**
    *   Any new write to a column **completely overwrites** the previous value, write time, and TTL.
    *   If you update a column without specifying a TTL, the new value becomes **permanent** (unless there's a default TTL on the table).

*   **Reading TTL Information:** You can check the remaining time until expiration for a non-null column using the `TTL()` function in a select statement.
    ```sql
    SELECT username, TTL(session_token) AS seconds_until_expire FROM users WHERE user_id = 123;
    ```

---

### Important Considerations and Best Practices

1.  **Clock Synchronization:** Cassandra nodes should have synchronized clocks (using NTP). If clocks are skewed, expiration behavior can become inconsistent across the cluster.

2.  **Tombstone Overhead:** Expired data becomes a tombstone. A high volume of expirations (e.g., millions of rows with short TTLs) can generate many tombstones, which can impact performance if they exist for longer than the `gc_grace_seconds` period (default: 10 days) before compaction handles them.

3.  **Immediate Consistency:** Data is not deleted the *instant* the TTL expires. It's only filtered out during **reads** and physically deleted during **compaction**. If no reads occur for a long time, the data will remain on disk until the next compaction, even though it's logically expired.

4.  **Use Case Driven:** TTL is perfect for use cases like:
    *   **Session data**
    *   **Cached data** (e.g., API responses)
    *   **Temporary logs or events**
    *   **Compliance requirements** where data must be purged after a certain period.

### Summary

In essence, Apache Cassandra's TTL is a **lazy expiration mechanism**. It doesn't use a background process to constantly scan and delete old data. Instead, it efficiently checks for expiration at read-time and relies on the normal compaction process to perform the physical deletion, making it very scalable for managing temporary data.