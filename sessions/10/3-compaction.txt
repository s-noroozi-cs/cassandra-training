Compaction
    Compaction is Cassandra's automatic process of merging multiple 
    data files (SSTables) into a single, new file to optimize read 
    performance and reclaim space from expired or deleted data.

How Data is Written
    When you write data to Cassandra, 
    it first goes to the commit log (for durability) and then 
    to an in-memory structure called a memtable. 
    When a memtable is full, it is flushed to disk as a read-only 
    file called an SSTable (Sorted String Table).

The Problem
    Over time, you accumulate many SSTables. A piece of data might be 
    spread across multiple SSTables, the original value in one, an 
    update in another, and a tombstone marking its deletion in a third. 
    This makes reads very slow because Cassandra has to check every 
    relevant SSTable to assemble the most recent state of the data.

The Solution - Compaction

    1. Merging SSTables: 
        It takes several smaller SSTables and merges them into one 
        larger, consolidated SSTable.

    2. Combining Data: 
        During the merge, it only keeps the most recent version of 
        each row and column.

    3. Dropping Expired Data:
        It discards any data that has exceeded its TTL.

    4. Dropping Tombstones: 
        It can remove tombstones (delete markers) once the data they 
        reference is older than gc_grace_seconds.

Why Compaction is Vital:

    1. Faster Reads: 
        Fewer SSTables to check = lower read latency

    2. Space Reclamation: 
        It frees up disk space used by outdated data

    3. Data Consistency: 
        It helps ensure data is consistent and old data doesn't reappear

Potential Negative Effects & Considerations

    1. Resource Consumption (CPU, I/O, Disk): 
        Compaction is a resource-intensive operation. 
        It reads and rewrites large amounts of data. On a busy cluster, 
        this can compete with application read/write requests, 
        potentially causing higher latency during the compaction process. 
        This is the classic trade-off: short-term pain for long-term gain.

    2. Disk Space Requirement: 
        During compaction, the system needs extra disk space. It must write 
        the new, compacted SSTable before it can delete the old ones. 
        You need to have enough free disk space 
        (often recommended to be 50% of total capacity) to handle these 
        operations without running out of space.

    3. Long-Running Compactions: 
        If a node falls behind (e.g., due to being down for maintenance), 
        it might come back and have a huge backlog of SSTables to compact. 
        This can lead to a long-running "compaction storm" that takes hours or 
        even days to complete, during which performance can be significantly 
        impacted.

Common Compaction Strategies:

    SizeTieredCompactionStrategy (STCS): 
        
        Definition: 
            The default strategy. STCS groups SSTables of similar size 
            and compacts them together into a larger SSTable. This process 
            creates a "tiered" effect of increasingly larger SSTables.

        How it Works:
            1. It triggers when a certain number (default: 4) of SSTables of 
            a similar size exist.

            2. It compacts these 4 SSTables into 1 larger one.

            3. Once there are 4 of these larger SSTables, they are 
            compacted into one even larger SSTable, and so on.

        Configuration (common options in table_definition):

            'min_threshold': 4 
                The number of same-sized SSTables needed to trigger 
                a compaction.

            'max_threshold': 32
                The maximum number of SSTables to compact at once.

            'bucket_high': 1.5

            'bucket_low': 0.5

        Effect & Best For:

            Pros: 
                Simple, efficient for write-intensive workloads 
                where reads are less frequent. It minimizes total 
                write I/O during compaction.

            Cons: 
                Can lead to temporary space amplification 
                (needs up to 50% free disk space during the process). 
                Can cause higher read latency if data is spread across 
                many large SSTables. Does not handle time-series data with 
                TTL well.

            Analogy: 
                Combining many small boxes into a few larger boxes.

    LeveledCompactionStrategy (LCS): 


        Definition: 
            Designed for read-heavy workloads. LCS uses a series of levels 
            to ensure that 90% of reads can be satisfied from a single, 
            optimal SSTable (Level 0).

        How it Works:

            Level 0 (L0): 
                New SSTables are created here. When a number of L0 SSTables 
                exist (sstable_size_in_mb / min_sstable_size), they are 
                compacted with the key range they overlap in Level 1.

            Level 1 and higher: 
                Each level is 10 times larger than the previous. SSTables 
                within a level are non-overlapping in their token ranges. 
                Compaction promotes SSTables to higher levels by merging them 
                with the existing non-overlapping SSTables in that level.

        Configuration:

            'sstable_size_in_mb': 160 - The target size for SSTables.

            'fanout_size': 10 - The size multiplier between levels.

        Effect & Best For:

            Pros: 
                Excellent and predictable read performance. Lower disk 
                space requirement than STCS (only ~10% overhead).

            Cons: 
                Significantly higher write amplification (more data is 
                rewritten during compaction). This can consume more I/O 
                and CPU, which can impact write throughput.

        Analogy: 
            A library filing system. New books (SSTables) arrive on a 
            cart (L0). They are then sorted and integrated onto specific, 
            non-overlapping shelves (L1, L2, etc.) based on their Dewey 
            Decimal number (token range).


    TimeWindowCompactionStrategy (TWCS): 
        
        Definition: 
            The ideal strategy for time-series data with regular TTL, 
            like our IoT sensor example.

        How it Works:
            1. You define a compaction_window_unit (e.g., 'HOURS', 'DAYS') 
            and compaction_window_size (e.g., 1).

            2. Within each time window, TWCS acts like STCS, compacting small 
            SSTables.

            3. Once a time window closes, all SSTables from that window 
            are compacted into a single, final SSTable. These SSTables 
            are never compacted with SSTables from other time windows.

        Configuration:

            'compaction_window_unit': 'DAYS'

            'compaction_window_size': 1

            'timestamp_resolution': 'MICROSECONDS' (usually default is fine)

        Effect & Best For:

            Pros: 
                Extremely efficient for time-series data. Minimal write 
                amplification for old data. TTL expiration is trivial â€“ 
                entire SSTables can be dropped when their data expires, 
                without any compaction cost.

            Cons: 
                Only suitable for time-series data where writes are always 
                sequential in time. Useless for data that is frequently 
                updated out-of-order.

            Analogy: 
                A historian putting each day's documents into a 
                separate, sealed box. After a day, the box is sealed 
                shut and never reopened. After 365 days, the oldest 
                box is simply thrown away.