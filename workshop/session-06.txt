Apache Cassandra Multi-Node Cluster (Single and Multiple Datacenters)

    Configuring Firewall Port Access

    Selecting a Name for the Datacenter
        Once you assign a name for a datacenter, you can’t change it later.
    
    Selecting the Nodes to Serve as Seed Nodes

        A seed provider is one of the nodes in the cluster that helps Cassandra nodes 
        to find each other and learn the topology of the ring. 
        This is a required parameter for a multi-node cluster.

        You specify the seed nodes(s) for a cluster by configuring 
        the seed_provider parameter in the cassandra.yaml file.

        seed_provider:
          - class_name: org.apache.cassandra.locator.SimpleSeedProvider
            parameters:
              - seeds: "192.168.177.132,192.168.177.135"

          You provide the list of seed nodes as a comma-delimited 
          set of IP addresses (“<ip1>, <ip2>, <ip3>”).

          You can make do with a single seed node per datacenter, 
          but the best practice is to have more than one seed node.

        The num_tokens Property
        
          The num_tokens property defines the number of tokens Cassandra assigns to a 
          specific node. The higher the number of tokens relative to the rest of the nodes, 
          the greater the amount of data this node will store. Since ideally all nodes are 
          of equal size, you want all nodes to have the same number of tokens.

          The initial_token property is a legacy parameter that you must leave alone. 
          If you specify the initial_token property, it’ll override the num_tokens property.

        The endpoint_snitch Option

          In a Cassandra cluster, a snitch serves two functions:

          1. It tells Cassandra about the network topology so it can 
            efficiently route its requests.
          
          2. It enables Cassandra to spread the data copies (replicas) around the cluster, 
            thus avoiding correlated failures. Cassandra uses datacenters and racks to 
            logically group a cluster’s nodes. It tries its best not to store multiple 
            replicas of the same piece of data on a single rack.

          Cassandra offers a half dozen snitches, but for production environments, 
          the go to option is the GossipingPropertyFileSnitch .
          
          When you select the GossipingPropertyFileSnitch option, you specify the datacenter 
          and the rack in the cassandra-rackdc.properties file on that node. Cassandra then 
          propagates this information to the other nodes via gossip.

  A Schema Version Mismatch
    Sometimes you’ll run into an error when creating a keyspace or a table, 
    where Cassandra complains about a version mismatch.
    Cassandra will create the keyspace or table despite this message. 
    When a schema disagreement occurs, follow these steps.
    
    1. Run the nodetool describecluster command
    2. Restart the unreachable node(s).
    3. Run the nodetoool describecluster command again, 
        and ensure that all nodes have the same version number. 
        The output of the command must show a single schema version 
        for all nodes in the cluster.


Modeling Around Queries and Not Around Relations

  The way to satisfy the two basic rules, especially the minimizing of the number of partitions, 
  is by modeling your database around your queries. 
  Unlike in a relational database, where you model around the relations among entities, 
  you model based on the queries you expect your database to support.
  When designing a data model, always start with the queries. You need to think in terms 
  of how the users are going to want to view the data and how they’ll search through the data.
  What the users are going to search for should be the primary key of the table, and the 
  information they want to view should be your columns. That’s all there’s to it. 
  You don’t need to worry about all the normal forms and relationships among the data, etc.
  
  To model around your queries , you need to do two things: 
    1. Find out the queries the database must support.
    2. Create appropriate tables.

  Determining the Queries
    There’s no single data model that serves all query cases. If you change the query 
    requirements ever so slightly, you’ll need to modify your data model. When determining 
    the queries you want a Cassandra database to support, think of the following types of 
    requirements in a query:

      # A query that requires unique values only in the result set
      # A query that wants to filter the results based on specific criteria
      # A query that wants to order the results 
      # A query that seeks to group the results

  Performance Limitations of Cassandra

    Write Limitations
      
      Cassandra offers a very fast write throughput, but there are a couple of key compromises 
      that enable it to do so, as explained in the following sections.

      # No Support for Traditional Transactions
          Cassandra does support lightweight transactions, but these transactions are expensive.
      
      # Overhead for Mutations and Deletes
        As you know by now, Cassandra stores its data in SSTables on disk. 
        SSTables are immutable data structures. When you update data, Cassandra spreads 
        the data across several SSTables. When you delete data, Cassandra creates 
        tombstones (markers to denote data that’s to be deleted) to ensure that it deletes 
        the data correctly across the cluster. A tombstone will suppress older data until 
        the database can run a compaction, which will remove the data for good.
        Both the spreading of data across the SSTables during updates and the creation of 
        tombstones during deletes means a higher overhead during read operations. 
        This leads to pressure to compact the SSTables by cleaning them up.

    Read Limitations

      No Support for Joins
        You can’t join data from multiple tables into a single query in Cassandra. 
        There are no foreign keys to facilitate table joins, as is true of relational databases.
        Instead of joining tables, you de-normalize your data, thus duplicating it based on 
        the expected queries. Alternatively, you can use another reporting technology such 
        as Apache Spark to perform the joins.

      Indexes Work Differently
        Cassandra performs its searches via the primary key of a table, which is unique 
        and helps identify a row very fast. Secondary indexes , employed by relational 
        databases to speed up queries, however, are a different story altogether, 
        and can negatively impact performance if you don’t use them for the limited use-cases 
        where they are fine.

      Only Eventual Consistency
        The key principle behind Cassandra’s data model is tunable consistency , 
        where the client applications determine the consistency of the data they require.
        Even though Cassandra automatically replicates data across the cluster, 
        there’s an inherent latency in replicating the data, and you’re bound by 
        the principle of eventual consistency. Eventual consistency, also called optimistic
        replication , achieves high availability in distributed computing architectures, 
        and informally guarantees that in the absence of newer updates to a data item, 
        eventually accessing that data item will return its last updated value.

        Consistency Conflict Resolution
          Since eventual consistency only guarantees that reads will eventually return 
          the same value and doesn’t make any safety guarantees, it can return a value 
          before it converges. To ensure replica convergence, an eventually consistency 
          system must reconcile the differences among multiple versions of the same data items, 
          by following this two-step procedure:
            
            1. Anti-entropy , which involves exchanging versions of data between the nodes
            2. Reconciliation , which involves choosing an appropriate final state of the data 
            when concurrent updates change that data
          
          There are several approaches to reconciling concurrent writes, such as the 
          “last writer wins” strategy, user-specified conflict handlers, and so on. 
          The database normally uses timestamps to detect the concurrency among the updates.