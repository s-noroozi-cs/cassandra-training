# Run the first node and keep it in background up and running
docker run --name cassandra-1 -p 9042:9042 -d cassandra:5.0.3
INSTANCE1=$(docker inspect --format="{{ .NetworkSettings.IPAddress }}" cassandra-1)
echo "Instance 1: ${INSTANCE1}"

# Run the second node
docker run --name cassandra-2 -p 9043:9042 -d -e CASSANDRA_SEEDS=$INSTANCE1 cassandra:5.0.3
INSTANCE2=$(docker inspect --format="{{ .NetworkSettings.IPAddress }}" cassandra-2)
echo "Instance 2: ${INSTANCE2}"

echo "Wait 60s until the second node joins the cluster"
sleep 60

# Run the third node
docker run --name cassandra-3 -p 9044:9042 -d -e CASSANDRA_SEEDS=$INSTANCE1,$INSTANCE2 cassandra:5.0.3
INSTANCE3=$(docker inspect --format="{{ .NetworkSettings.IPAddress }}" cassandra-3)



$ docker exec cassandra-1 nodetool status

UN means Up and Normal


$ docker exec -it cassandra-1 cqlsh


# show all existing keyspaces 

cqlsh> describe keyspaces


# Before you begin creating tables and inserting data, first create a keyspace in your local datacenter, 
# which should replicate data 3 times

# The strategy defines how data is replicated in different datacenters. 
# This is the recommended strategy for all user created keyspaces.

cqlsh> CREATE KEYSPACE learn_cassandra
  WITH REPLICATION = { 
   'class' : 'NetworkTopologyStrategy',
   'datacenter1' : 3 
  };


# Why should you start with 3 nodes?
# It’s recommended to have at least 3 nodes or more. One reason is, in case you need strong consistency, 
# you need to get confirmed data from at least 2 nodes. Or if 1 node goes down, 
# your cluster would still be available because the 2 remaining nodes are up and running.


Cassandra Architecture

    Cassandra is a decentralized multi-node database that physically spans separate locations 
    and uses replication and partitioning to infinitely scale reads and writes.

Decentralization
    Cassandra is decentralized because no node is superior to other nodes, 
    and every node acts in different roles as needed without any central controller.

Every Node Is a Coordinator
    Data is replicated to different nodes. If certain data is requested, 
    a request can be processed from any node.

    This initial request receiver becomes the coordinator node for that request. 
    If other nodes need to be checked to ensure consistency then the 
    coordinator requests the required data from replica nodes.

    The coordinator can calculate which node contains 
    the data using a so-called consistent hashing algorithm.

    The coordinator is responsible for many things, 
    such as request batching, repairing data, or retries for reads and writes.

Data Partitioning
    “[Partitioning] is a method of splitting and storing a single logical dataset 
    in multiple databases. By distributing the data among multiple machines, 
    a cluster of database systems can store larger datasets 
    and handle additional requests.

    As with many other databases, you store data in Cassandra in a predefined schema. 
    You need to define a table with columns and types for each column.

    Additionally, you need to think about the primary key of your table. 
    A primary key is mandatory and ensures data is uniquely identifiable 
    by one or multiple columns.

    The concept of primary keys is more complex in Cassandra than in 
    traditional databases like MySQL. 
    
    In Cassandra, the primary key consists of 2 parts:

        1. a mandatory partition key
        2. an optional set of clustering columns


cqlsh> CREATE TABLE learn_cassandra.users_by_country (
    country text,
    user_email text,
    first_name text,
    last_name text,
    age smallint,
    PRIMARY KEY ((country), user_email)
);

Let’s fill the table with some data:

------------------------------------------------------

cqlsh> 
INSERT INTO learn_cassandra.users_by_country (country,user_email,first_name,last_name,age)
  VALUES('US', 'john@email.com', 'John','Wick',55);

INSERT INTO learn_cassandra.users_by_country (country,user_email,first_name,last_name,age)
  VALUES('UK', 'peter@email.com', 'Peter','Clark',65);

INSERT INTO learn_cassandra.users_by_country (country,user_email,first_name,last_name,age)
  VALUES('UK', 'bob@email.com', 'Bob','Sandler',23);

INSERT INTO learn_cassandra.users_by_country (country,user_email,first_name,last_name,age)
  VALUES('UK', 'alice@email.com', 'Alice','Brown',26);

------------------------------------------------------

    If you’re used to designing traditional relational database tables 
    like it’s taught in school or university, you might be surprised. 
    Why would you use country as an essential part of the primary key?

    This example will make sense after you understand 
    the basics of partitioning in Cassandra.

    Partitioning is the foundation for scalability, 
    and it is based on the partition key. In this example, 
    partitions are created based on country. 
    All rows with the country US are placed in a partition. 
    All other rows with the country UK will be stored in another partition.

    The partition key is vital to distribute data evenly between nodes 
    and essential when reading the data. The previously defined schema 
    is designed to be queried by country because country is the partition key.

    A query that selects rows by country performs well:
    
    ------------------------------------------------------
    cqlsh> 
        SELECT * FROM learn_cassandra.users_by_country WHERE country='US';
    ------------------------------------------------------

    In your cqlsh shell, you will send a request only to a 
    single Cassandra node by default. This is called a consistency level of one, 
    which enables excellent performance and scalability.

    If you access Cassandra differently, the default consistency level might not be one.

    What does consistency level of one mean?

        A consistency level of one means that only a single node is 
        asked to return the data. With this approach, 
        you will lose strong consistency guarantees and 
        instead experience eventual consistency.

    
    Let's create another table. This one has a partition defined 
    only by the user_email column:

    cqlsh> 
        CREATE TABLE learn_cassandra.users_by_email (
            user_email text,
            country text,
            first_name text,
            last_name text,
            age smallint,
            PRIMARY KEY (user_email)
        );

    Now let’s fill this table with some records:

    cqlsh> 
        INSERT INTO learn_cassandra.users_by_email (user_email, country,first_name,last_name,age)
        VALUES('john@email.com', 'US', 'John','Wick',55);

        INSERT INTO learn_cassandra.users_by_email (user_email,country,first_name,last_name,age)
        VALUES('peter@email.com', 'UK', 'Peter','Clark',65); 

        INSERT INTO learn_cassandra.users_by_email (user_email,country,first_name,last_name,age)
        VALUES('bob@email.com', 'UK', 'Bob','Sandler',23);

        INSERT INTO learn_cassandra.users_by_email (user_email,country,first_name,last_name,age)
        VALUES('alice@email.com', 'UK', 'Alice','Brown',26);

    This time, each row is put in its own partition. 4 partitions :-)

    This is not bad, per se. If you want to optimize for getting 
    data by email only, it's a good idea:

    cqlsh> 
        SELECT * FROM learn_cassandra.users_by_email WHERE user_email='alice@email.com';

    If you set up your table with a partition key for user_email 
    and want to get all users by age, you would need to get the 
    data from all partitions because the partitions were created by user_email.

    Talking to all nodes is expensive and can cause performance issues on a large cluster.

    Cassandra tries to avoid harmful queries. If you want to filter 
    by a column that is not a partition key, you need to tell Cassandra
    explicitly that you want to filter by a non-partition key column:

    cqlsh> 
        SELECT * FROM learn_cassandra.users_by_email WHERE age=26 ALLOW FILTERING;

    Without ALLOW FILTERING, the query would not be executed to prevent 
    harm to the cluster by accidentally running expensive queries. 
    Executing queries without conditions (like without a WHERE clause) 
    or with conditions that don’t use the partition key, 
    are costly and should be avoided to prevent performance bottlenecks.

    But how do you get all the rows from the table in a scalable way?

    If you can, partition by a value like country. If you know all the countries, 
    you can then iterate over all available countries, send a query for each one, 
    and collect the results in your application.

    What does strong consistency mean?

        In contrast to eventual consistency, strong consistency 
        means only one state of your data can be observed at 
        any time in any location.

        For example, when consistency is critical, like in a banking domain, 
        you want to be sure that everything is correct. 
        You would rather accept a decrease in availability and 
        increase of latency to ensure correctness.

    Tune for Consistency by Setting up a Strong Consistency Application

        There is a very important formula that if true guarantees strong consistency:
        -------------------------------
        [read-consistency-level] + [write-consistency-level] > [replication-factor]
        -------------------------------

        What does consistency level mean?

            Consistency level means how many nodes need to 
            acknowledge a read or a write query.

            You can shift read and write consistency levels to your 
            favor if you want to keep strong consistency. 
            Or you even give up strong consistency for better performance, 
            which is also called eventual consistency

        For a read-heavy system, it’s recommended to keep read consistency 
        low because reads happen more often than writes. 
        Let's say you have a replication factor of 3. The formula would look like this:
        
        -------------------------------
        1 + [write-consistency-level] > 3
        -------------------------------

        Therefore, the write consistency has to be set to 3 
        to have a strongly consistent system.

        For a write-heavy system, you can do the same. 
        Set the write consistency level to 1 and 
        the read consistency level to 3.
    

        This decision needs to be reflected in all the applications 
        that access your Cassandra data because, on a query level, 
        you need to set the required consistency level.

        You set the replication factor of 3. Therefore, 
        you can use a consistency level of ALL or THREE:

        -------------------------------
        cqlsh> 
            CONSISTENCY ALL;
            SELECT * FROM learn_cassandra.users_by_country WHERE country='US';
        -------------------------------

        Tune for Performance by Using Eventual Consistency

            If you don't need to be strongly consistent, 
            you can reduce the consistency level for queries 
            to 1 to gain performance:

        -------------------------------
        cqlsh> 
            CONSISTENCY ONE;
            SELECT * FROM learn_cassandra.users_by_country WHERE country='US';
        -------------------------------

        Eventually, the data will be spread to all replicas and this will 
        ensure eventual consistency. How fast data will be made 
        consistent depends on different mechanics that sync data between nodes.
